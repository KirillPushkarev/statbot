{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to SQL - Questions generation and testing for the Statbot-Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/text-to-sql-learning-to-query-tables-with-natural-language-7d714e60a70d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you plan to add views to generate questions, you should add rows to the csv file in input_data/INDICATORS_VIEW.csv. Do not fill all columns (indicator_id, a short description, question type (as 1), name of the view and column name of the view value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "NB_SAMPLES = 1 # number of samples per type (default: 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Zurich and Basel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "INPUT_FOLDER = 'input_data'\n",
    "INDICATORS_FILE = 'EN_INDICATORS.csv'\n",
    "INDICATORS_VALUES_FILE = 'EN_INDICATOR_VALUES.csv'\n",
    "INDICATORS_VIEWS_FILE = 'INDICATORS_VIEWS.csv'\n",
    "SPATIALUNIT_FILE = 'EN_T_SPATIALUNIT.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of natural language questions & SQL Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in a dataset with indicator metadata and short descriptions which can be used to generate questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = pd.read_csv(os.path.join(INPUT_FOLDER, INDICATORS_FILE))\n",
    "indicators.columns = [c.lower() for c in indicators.columns]\n",
    "indicators = indicators.rename(columns={\"name\": \"indicator_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = pd.read_csv(os.path.join(INPUT_FOLDER, INDICATORS_VIEWS_FILE))\n",
    "indicators = indicators.merge(descriptions, on='indicator_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a single dataset with all information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Create a combined dataset containing all the information (values, indicator labels, spatial unit labels)  to make the generation of the question / sql pairs easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators_values = pd.read_csv(os.path.join(INPUT_FOLDER, INDICATORS_VALUES_FILE))\n",
    "indicators_values.columns = [c.lower() for c in indicators_values.columns]\n",
    "gp_data = indicators_values.merge(indicators, on='indicator_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_units = pd.read_csv(os.path.join(INPUT_FOLDER, SPATIALUNIT_FILE))\n",
    "spatial_units.columns = [c.lower() for c in spatial_units.columns]\n",
    "spatial_units = spatial_units.rename(columns={'name': 'municipality_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_data = gp_data.merge(spatial_units, on='spatialunit_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset with random values, years and municipalities per indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To fill in the questions and queries, random values, years and municipalities are drawn for each indicator. These are then integrated into the templates dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_units = spatial_units[['spatialunit_id', 'municipality_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_data = gp_data[gp_data['type_id']==1]\n",
    "gp_data = gp_data[gp_data['question_type']<=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take one random sample of each group\n",
    "grouping_columns = ['indicator_id', 'indicator_name', 'short_description', 'question_type']\n",
    "grouped_samples = gp_data.groupby(by=grouping_columns)\n",
    "\n",
    "sample_columns = grouping_columns + ['value', 'year', 'spatialunit_id', 'view_name', 'view_column_value']\n",
    "samples = grouped_samples.sample(n=NB_SAMPLES).reset_index()[sample_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = samples.merge(spatial_units, on='spatialunit_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indicator_id</th>\n",
       "      <th>indicator_name</th>\n",
       "      <th>short_description</th>\n",
       "      <th>question_type</th>\n",
       "      <th>value</th>\n",
       "      <th>year</th>\n",
       "      <th>spatialunit_id</th>\n",
       "      <th>view_name</th>\n",
       "      <th>view_column_value</th>\n",
       "      <th>municipality_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>385</td>\n",
       "      <td>Access by bus [% of inhabitants]</td>\n",
       "      <td>share of people living in proximity of a busstop</td>\n",
       "      <td>1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2009</td>\n",
       "      <td>19</td>\n",
       "      <td>accessibility_bus</td>\n",
       "      <td>access_by_bus</td>\n",
       "      <td>Dachsen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>386</td>\n",
       "      <td>Access by suburban train [% of inhabitants]</td>\n",
       "      <td>share of people living in proximity of a train...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>2014</td>\n",
       "      <td>89</td>\n",
       "      <td>accessibility_train</td>\n",
       "      <td>access_by_suburban_train</td>\n",
       "      <td>Hinwil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>399</td>\n",
       "      <td>Passenger cars per 1000 inhabitants [no.]</td>\n",
       "      <td>number of cars per capita</td>\n",
       "      <td>2</td>\n",
       "      <td>539.9</td>\n",
       "      <td>2016</td>\n",
       "      <td>114</td>\n",
       "      <td>number_of_passenger_cars</td>\n",
       "      <td>passenger_cars_per_1000_inhabitants</td>\n",
       "      <td>Uetikon a.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>401</td>\n",
       "      <td>Accessibility by suburban train+bus [% of inha...</td>\n",
       "      <td>share of people living in proximity of a train...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>146</td>\n",
       "      <td>accessibility_train_and_bus</td>\n",
       "      <td>access_by_suburban_train_and_bus</td>\n",
       "      <td>Ellikon a.d.Th.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>480</td>\n",
       "      <td>public transport share (modal split) [%]</td>\n",
       "      <td>share of public transport in traffic movements...</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>155</td>\n",
       "      <td>public_transport_share</td>\n",
       "      <td>public_transport_share_modal_split</td>\n",
       "      <td>Seuzach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>481</td>\n",
       "      <td>MIV share (modal split) [%]</td>\n",
       "      <td>share of motorised private transport in traffi...</td>\n",
       "      <td>1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>60</td>\n",
       "      <td>miv_share</td>\n",
       "      <td>miv_share_modal_split</td>\n",
       "      <td>Winkel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>601</td>\n",
       "      <td>PW new registrations per 1000 inhabitants [amo...</td>\n",
       "      <td>number of newly registered cars</td>\n",
       "      <td>2</td>\n",
       "      <td>38.3</td>\n",
       "      <td>2005</td>\n",
       "      <td>59</td>\n",
       "      <td>amount_new_pw_registrations</td>\n",
       "      <td>amount_new_pw_registrations_per_1000_inhabitants</td>\n",
       "      <td>Wil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>606</td>\n",
       "      <td>Hybrid motor cars stock [%]</td>\n",
       "      <td>share of hybrid vehicles</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2009</td>\n",
       "      <td>128</td>\n",
       "      <td>share_hybrid_cars</td>\n",
       "      <td>share_of_hybrid_cars</td>\n",
       "      <td>Wildberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>607</td>\n",
       "      <td>Electric motor cars stock [%]</td>\n",
       "      <td>share of electric vehicles</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2019</td>\n",
       "      <td>48</td>\n",
       "      <td>share_electric_cars</td>\n",
       "      <td>share_electric_cars</td>\n",
       "      <td>Hoeri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>611</td>\n",
       "      <td>New registrations of hybrid motor cars [%]</td>\n",
       "      <td>share of hybrid vehicles within the newly regi...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2018</td>\n",
       "      <td>144</td>\n",
       "      <td>new_hybrid_car_registrations</td>\n",
       "      <td>new_hybrid_car_registrations</td>\n",
       "      <td>Dinhard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>612</td>\n",
       "      <td>New registrations electric motor cars [%]</td>\n",
       "      <td>share of electric vehicles within the newly re...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>61</td>\n",
       "      <td>new_electric_car_registrations</td>\n",
       "      <td>new_electric_car_registrations</td>\n",
       "      <td>Bachs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>996</td>\n",
       "      <td>Total new registrations of electric and hybri...</td>\n",
       "      <td>Total new registrations of electric and hybri...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2006</td>\n",
       "      <td>134</td>\n",
       "      <td>total_registrations_electric_hybrid_cars</td>\n",
       "      <td>total_reg_electric_cars</td>\n",
       "      <td>Moenchaltorf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>997</td>\n",
       "      <td>Total of electric and hybrid motor cars stock [%]</td>\n",
       "      <td>Total of electric and hybrid motor cars stock [%]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>88</td>\n",
       "      <td>total_electric_hybrid_cars</td>\n",
       "      <td>total_electric_cars</td>\n",
       "      <td>Grueningen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>998</td>\n",
       "      <td>Charging stations of electronic cars per 1000 ...</td>\n",
       "      <td>Charging stations of electronic cars per 1000 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>26</td>\n",
       "      <td>charging_stations_electric_cars_per_inh</td>\n",
       "      <td>charging_stations_per_inh</td>\n",
       "      <td>Humlikon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>999</td>\n",
       "      <td>Charging stations of electronic cars [no.]</td>\n",
       "      <td>Charging stations of electronic cars [no.]</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>199</td>\n",
       "      <td>charging_stations_electric_cars</td>\n",
       "      <td>charging_stations</td>\n",
       "      <td>Horgen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    indicator_id                                     indicator_name  \\\n",
       "0            385                   Access by bus [% of inhabitants]   \n",
       "1            386        Access by suburban train [% of inhabitants]   \n",
       "2            399         Passenger cars per 1000 inhabitants [no.]    \n",
       "3            401  Accessibility by suburban train+bus [% of inha...   \n",
       "4            480          public transport share (modal split) [%]    \n",
       "5            481                       MIV share (modal split) [%]    \n",
       "6            601  PW new registrations per 1000 inhabitants [amo...   \n",
       "7            606                        Hybrid motor cars stock [%]   \n",
       "8            607                     Electric motor cars stock [%]    \n",
       "9            611        New registrations of hybrid motor cars [%]    \n",
       "10           612         New registrations electric motor cars [%]    \n",
       "11           996   Total new registrations of electric and hybri...   \n",
       "12           997  Total of electric and hybrid motor cars stock [%]   \n",
       "13           998  Charging stations of electronic cars per 1000 ...   \n",
       "14           999        Charging stations of electronic cars [no.]    \n",
       "\n",
       "                                    short_description  question_type  value  \\\n",
       "0    share of people living in proximity of a busstop              1    3.8   \n",
       "1   share of people living in proximity of a train...              1    7.9   \n",
       "2                           number of cars per capita              2  539.9   \n",
       "3   share of people living in proximity of a train...              1    0.0   \n",
       "4   share of public transport in traffic movements...              1   14.0   \n",
       "5   share of motorised private transport in traffi...              1   83.0   \n",
       "6                     number of newly registered cars              2   38.3   \n",
       "7                            share of hybrid vehicles              1    0.2   \n",
       "8                          share of electric vehicles              1    0.4   \n",
       "9   share of hybrid vehicles within the newly regi...              1    4.2   \n",
       "10  share of electric vehicles within the newly re...              1    0.0   \n",
       "11   Total new registrations of electric and hybri...              1    0.9   \n",
       "12  Total of electric and hybrid motor cars stock [%]              1    0.0   \n",
       "13  Charging stations of electronic cars per 1000 ...              1    0.0   \n",
       "14        Charging stations of electronic cars [no.]               1   15.0   \n",
       "\n",
       "    year  spatialunit_id                                 view_name  \\\n",
       "0   2009              19                         accessibility_bus   \n",
       "1   2014              89                       accessibility_train   \n",
       "2   2016             114                  number_of_passenger_cars   \n",
       "3   2001             146               accessibility_train_and_bus   \n",
       "4   2016             155                    public_transport_share   \n",
       "5   2013              60                                 miv_share   \n",
       "6   2005              59               amount_new_pw_registrations   \n",
       "7   2009             128                         share_hybrid_cars   \n",
       "8   2019              48                       share_electric_cars   \n",
       "9   2018             144              new_hybrid_car_registrations   \n",
       "10  2003              61            new_electric_car_registrations   \n",
       "11  2006             134  total_registrations_electric_hybrid_cars   \n",
       "12  2004              88                total_electric_hybrid_cars   \n",
       "13  2021              26   charging_stations_electric_cars_per_inh   \n",
       "14  2021             199           charging_stations_electric_cars   \n",
       "\n",
       "                                   view_column_value municipality_name  \n",
       "0                                      access_by_bus           Dachsen  \n",
       "1                           access_by_suburban_train            Hinwil  \n",
       "2                passenger_cars_per_1000_inhabitants      Uetikon a.S.  \n",
       "3                   access_by_suburban_train_and_bus   Ellikon a.d.Th.  \n",
       "4                 public_transport_share_modal_split           Seuzach  \n",
       "5                              miv_share_modal_split            Winkel  \n",
       "6   amount_new_pw_registrations_per_1000_inhabitants               Wil  \n",
       "7                               share_of_hybrid_cars          Wildberg  \n",
       "8                                share_electric_cars             Hoeri  \n",
       "9                       new_hybrid_car_registrations           Dinhard  \n",
       "10                    new_electric_car_registrations             Bachs  \n",
       "11                           total_reg_electric_cars      Moenchaltorf  \n",
       "12                               total_electric_cars        Grueningen  \n",
       "13                         charging_stations_per_inh          Humlikon  \n",
       "14                                 charging_stations            Horgen  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the vectors in the templates\n",
    "def create_question_query(sample: pd.Series) -> Tuple[List[str], List[str]]:\n",
    "    '''\n",
    "    From a sample values, create 7 questions and 7 associated queries\n",
    "    Args:\n",
    "        - sample: row of random observations values\n",
    "    Return:\n",
    "        - questions: list of question generated with the values from sample\n",
    "        - queries: : list of queries generated with the values from sample\n",
    "    '''\n",
    "\n",
    "    indicator, view, view_column, random_value, indicator_id, indicator_year, municipality = sample[\n",
    "        ['short_description', 'view_name', 'view_column_value', 'value', 'indicator_id', 'year', 'municipality_name']\n",
    "    ].values\n",
    "    \n",
    "    questions = [\n",
    "        f\"How high is the {indicator} in {municipality} in the year {indicator_year}?\", # 0\n",
    "        f\"Which municipality has the highest {indicator}?\", # 1\n",
    "        f\"Which municipality has the minimum {indicator}?\", # 2\n",
    "        f\"What are the highest, lowest and average {indicator}?\", # 3\n",
    "        f\"How many municipalities have a {indicator} higher than {random_value} per year?\", # 4\n",
    "        f\"How high is the total {indicator} in the Canton Zurich in the year {indicator_year}?\", # 5\n",
    "        f\"Which region had the lowest {indicator} in the year {indicator_year}?\" # 6\n",
    "    ]\n",
    "    \n",
    "    queries = [\n",
    "        # 0\n",
    "        f\"SELECT T1.{view_column} \\\n",
    "        FROM {view} AS T1 \\\n",
    "        JOIN spatialunit AS T2 ON T1.spatialunit_id = T2.spatialunit_id \\\n",
    "        WHERE T2.name LIKE '{municipality}' AND T1.year = {indicator_year}\", \n",
    "        \n",
    "        # 1\n",
    "        f\"SELECT T2.name \\\n",
    "        FROM spatialunit AS T2 \\\n",
    "        JOIN {view} AS T1 ON T2.spatialunit_id = T1.spatialunit_id \\\n",
    "        ORDER BY T1.{view_column} DESC LIMIT 1\",\n",
    "        \n",
    "        # 2\n",
    "        f\"SELECT T2.name \\\n",
    "        FROM spatialunit AS T2 \\\n",
    "        JOIN {view} AS T1 ON T2.spatialunit_id = T1.spatialunit_id \\\n",
    "        ORDER BY T1.{view_column} ASC LIMIT 1\",\n",
    "        \n",
    "        # 3\n",
    "        f\"SELECT MAX(T1.{view_column}::numeric), \\\n",
    "        MIN(T1.{view_column}::numeric), AVG(T1.{view_column}::numeric) \\\n",
    "        FROM {view} AS T1\",\n",
    "        \n",
    "        # 4\n",
    "        f\"SELECT T1.year, COUNT(*) \\\n",
    "        FROM {view} AS T1 \\\n",
    "        JOIN spatialunit AS T2 ON T1.spatialunit_id = T2.spatialunit_id \\\n",
    "        WHERE T1.{view_column}::numeric > {random_value} AND T2.type_id = 1 \\\n",
    "        GROUP BY T1.year\",\n",
    "        \n",
    "        # 5\n",
    "        f\"SELECT T1.{view_column} FROM {view} AS T1 \\\n",
    "        JOIN spatialunit AS T2 ON T1.spatialunit_id = T2.spatialunit_id \\\n",
    "        WHERE T2.type_id = 8 AND T1.year = {indicator_year}\",\n",
    "        \n",
    "        # 6\n",
    "        f\"SELECT T2.name \\\n",
    "        FROM {view} AS T1 \\\n",
    "        JOIN spatialunit AS T2 ON T1.spatialunit_id = T2.spatialunit_id \\\n",
    "        WHERE T2.type_id = 4 AND T1.year = {indicator_year} \\\n",
    "        ORDER BY T1.{view_column} \\\n",
    "        LIMIT 1\"\n",
    "    ]\n",
    "    return questions, queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 7 questions and queries for each sample\n",
    "all_questions, all_queries = [], []\n",
    "for _, sample in samples.iterrows():   \n",
    "    questions, queries = create_question_query(sample)\n",
    "    all_questions.extend(questions)\n",
    "    all_queries.extend(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save questions and queries\n",
    "df = pd.DataFrame({'questions': all_questions, 'queries': all_queries})\n",
    "df.to_csv(\"questions_queries_python.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the SQL queries on Postgres (Optionnal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this if you want to test the queries in postgres (you will need an up to date postgres database)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_API_SECRET=%env NER_API_SECRET\n",
    "API_KEY=%env API_KEY\n",
    "DB_USER=%env DB_USER\n",
    "DB_PW=%env DB_PW\n",
    "DB_HOST=%env DB_HOST\n",
    "DB_PORT=%env DB_PORT\n",
    "DB_SCHEMA=\"public\"\n",
    "DB='hack_zurich'\n",
    "DRIVERNAME = \"postgresql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting with engine Engine(postgresql://postgres:***@database-1.cluster-cuqkxqloyykq.eu-central-1.rds.amazonaws.com:5432/hack_zurich)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22988/3535624919.py:3: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\n",
      "  sqlalchemy.engine.url.URL(\n"
     ]
    }
   ],
   "source": [
    "# Connection with sqalchemy database\n",
    "engine = sqlalchemy.create_engine(\n",
    "    sqlalchemy.engine.url.URL(\n",
    "        drivername=DRIVERNAME,\n",
    "        username=DB_USER,\n",
    "        password=DB_PW,\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        database=DB,\n",
    "    ),\n",
    "    echo_pool=True,\n",
    ")\n",
    "print(\"connecting with engine \" + str(engine))\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv containing the queries\n",
    "df = pd.read_csv(\"questions_queries_python.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(df: pd.DataFrame, query_number: int) -> None:\n",
    "    '''\n",
    "    Run a query on the database and prints the associted question and answer\n",
    "    Args:\n",
    "        - df: dataframe with all random samples\n",
    "        - query_number: index of the row of (question, query) to select\n",
    "    '''\n",
    "    question = df['questions'].iloc[query_number]\n",
    "    query = df['queries'].iloc[query_number]\n",
    "    answer = connection.execute(query)\n",
    "    \n",
    "    print(f\"Question {query_number}: {question}\")\n",
    "    print(f\"Answer {query_number}: {[r for r in answer]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run one query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 6: Which region had the lowest share of people living in proximity of a busstop in the year 2014?\n",
      "Answer 6: [('Region Zimmerberg',)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_query(df, query_number=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run all queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 0: How high is the share of people living in proximity of a busstop in Dorf in the year 2014?\n",
      "Answer 0: [('90.5',)]\n",
      "\n",
      "Question 1: Which municipality has the highest share of people living in proximity of a busstop?\n",
      "Answer 1: [('Faellanden',)]\n",
      "\n",
      "Question 2: Which municipality has the minimum share of people living in proximity of a busstop?\n",
      "Answer 2: [('Andelfingen',)]\n",
      "\n",
      "Question 3: What are the highest, lowest and average share of people living in proximity of a busstop?\n",
      "Answer 3: [(Decimal('99.6'), Decimal('0'), Decimal('54.4117080745341615'))]\n",
      "\n",
      "Question 4: How many municipalities have a share of people living in proximity of a busstop higher than 90.5 per year?\n",
      "Answer 4: [(2013, 26), (2003, 20), (2015, 26), (2008, 20), (2014, 25), (2010, 23), (2007, 17), (2002, 20), (2004, 20), (2006, 16), (2000, 17), (2011, 26), (2001, 18), (2012, 27), (2009, 19), (2005, 21)]\n",
      "\n",
      "Question 5: How high is the total share of people living in proximity of a busstop in the Canton Zurich in the year 2014?\n",
      "Answer 5: [('48.3',)]\n",
      "\n",
      "Question 6: Which region had the lowest share of people living in proximity of a busstop in the year 2014?\n",
      "Answer 6: [('Region Zimmerberg',)]\n",
      "\n",
      "Question 7: How high is the share of people living in proximity of a trainstation in Elgg (bis 2017) in the year 2015?\n",
      "Answer 7: [('10',)]\n",
      "\n",
      "Question 8: Which municipality has the highest share of people living in proximity of a trainstation?\n",
      "Answer 8: [('Thalheim a.d.Th.',)]\n",
      "\n",
      "Question 9: Which municipality has the minimum share of people living in proximity of a trainstation?\n",
      "Answer 9: [('Freienstein-Teufen',)]\n",
      "\n",
      "Question 10: What are the highest, lowest and average share of people living in proximity of a trainstation?\n",
      "Answer 10: [(Decimal('85.2'), Decimal('0'), Decimal('6.2056211180124224'))]\n",
      "\n",
      "Question 11: How many municipalities have a share of people living in proximity of a trainstation higher than 10.0 per year?\n",
      "Answer 11: [(2013, 23), (2003, 32), (2015, 23), (2008, 28), (2014, 21), (2010, 23), (2007, 31), (2002, 32), (2004, 31), (2006, 32), (2000, 34), (2011, 25), (2001, 39), (2012, 22), (2009, 27), (2005, 32)]\n",
      "\n",
      "Question 12: How high is the total share of people living in proximity of a trainstation in the Canton Zurich in the year 2015?\n",
      "Answer 12: [('3.8',)]\n",
      "\n",
      "Question 13: Which region had the lowest share of people living in proximity of a trainstation in the year 2015?\n",
      "Answer 13: [('Region Zuerich',)]\n",
      "\n",
      "Question 14: How high is the number of cars per capita in Zell in the year 2015?\n",
      "Answer 14: [('533.7',)]\n",
      "\n",
      "Question 15: Which municipality has the highest number of cars per capita?\n",
      "Answer 15: [('Dielsdorf',)]\n",
      "\n",
      "Question 16: Which municipality has the minimum number of cars per capita?\n",
      "Answer 16: [('Rickenbach',)]\n",
      "\n",
      "Question 17: What are the highest, lowest and average number of cars per capita?\n",
      "Answer 17: [(Decimal('805.1'), Decimal('182.8'), Decimal('563.4521439915299100'))]\n",
      "\n",
      "Question 18: How many municipalities have a number of cars per capita higher than 533.7 per year?\n",
      "Answer 18: [(2013, 140), (2003, 110), (2015, 135), (2008, 122), (2014, 138), (2010, 130), (2019, 123), (2007, 124), (2002, 108), (2004, 121), (2006, 125), (2020, 122), (2011, 132), (2017, 133), (2016, 135), (2012, 139), (2018, 129), (2009, 126), (2005, 115)]\n",
      "\n",
      "Question 19: How high is the total number of cars per capita in the Canton Zurich in the year 2015?\n",
      "Answer 19: [('488.6',)]\n",
      "\n",
      "Question 20: Which region had the lowest number of cars per capita in the year 2015?\n",
      "Answer 20: [('Region Zuerich',)]\n",
      "\n",
      "Question 21: How high is the share of people living in proximity of a trainstation or busstop in Buch a.I. in the year 2013?\n",
      "Answer 21: [('0',)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    run_query(df, i)\n",
    "    if i>20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate paraphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"questions_queries_python.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076bcff48ed54fb99d7f79fef7ca86bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ML-Model taken from https://github.com/Vamsi995/Paraphrase-Generator\n",
    "# https://huggingface.co/Vamsi/T5_Paraphrase_Paws\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")  \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paraphrases(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Script for creating paraphrases and thus expanding the q&a pairs generated through the first script\n",
    "    At the time of writing it generates from 90 initial q&a pairs, around \n",
    "\n",
    "    ML-Model taken from https://github.com/Vamsi995/Paraphrase-Generator\n",
    "    https://huggingface.co/Vamsi/T5_Paraphrase_Paws\n",
    "\n",
    "    Version 0.1.1 - 15.09.2021\n",
    "    Christian Ruiz - Statistisches Amt Kanton Zürich\n",
    "    CC0\n",
    "    \n",
    "    History \n",
    "    Version 0.1.2 -15.09.2021 - Umlaut-corrections for the SQL-queries\n",
    "    Version 0.1.1 -15.09.2021 - First version public\n",
    "    '''\n",
    "    output_df = df\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        sentence=df['questions'].iloc[i]\n",
    "        print(i, \" \", sentence)\n",
    "        text =  \"paraphrase: \" + sentence + \" </s>\"\n",
    "\n",
    "        encoding = tokenizer.encode_plus(text, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "        input_ids, attention_masks = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids, attention_mask=attention_masks,\n",
    "            max_length=256,\n",
    "            do_sample=True,\n",
    "            top_k=120,\n",
    "            top_p=0.95,\n",
    "            early_stopping=True,\n",
    "            num_return_sequences=8\n",
    "        )\n",
    "\n",
    "        for output in outputs:\n",
    "            line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "            output_df = output_df.append({'questions': line, 'queries': df['queries'].iloc[i]}, ignore_index=True)\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   Get cases in the last 3 months\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\pycharmprojects\\statbot\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   Show the cases 2021 on climate change\n",
      "2   Show the Deeds of the LDP Party\n",
      "3   Show the most popular categories of cases in 2020\n",
      "4   Give out links to all Eric Weber cases\n",
      "5   What political parties are there?\n"
     ]
    }
   ],
   "source": [
    "output_df = generate_paraphrases(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjustments\n",
    "output_df = output_df[['questions','queries']]\n",
    "output_df['questions'] = output_df['questions'].str.lower()\n",
    "output_df = output_df.drop_duplicates()\n",
    "\n",
    "# Replace the Umlaut in the SQL-queries for ValueNet\n",
    "output_df['queries'] = output_df['queries'].str.replace(\"ü\", \"ue\")\n",
    "output_df['queries'] = output_df['queries'].str.replace(\"ä\", \"ae\")\n",
    "output_df['queries'] = output_df['queries'].str.replace(\"ö\", \"oe\")\n",
    "\n",
    "# Save paraphrases\n",
    "output_df.to_csv(\"questions_queries_paraphrases.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to valunet preprocessing format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valuenet errors when tokenising the SQL with `::numeric`, hence we remove it here. \n",
    "If you query a PostgreSQL database again with these queries, be mindful that you might need the `::numeric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv containing the queries\n",
    "#df = pd.read_csv(\"questions_queries_python.csv\")\n",
    "df = pd.read_csv(\"questions_queries_paraphrases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_valuenet_format(df: pd.DataFrame) -> list:\n",
    "    handmade_data = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        query = row['queries'].replace('::numeric', '')\n",
    "        row_dict = {\n",
    "            'db_id': 'hack_zurich',\n",
    "            'query': query,\n",
    "            'question': row['questions']\n",
    "        }\n",
    "        handmade_data.append(row_dict)\n",
    "    return handmade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "handmade_data = df_to_valuenet_format(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save question_queries in the format required by valuenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RATIO = 0.8\n",
    "training_samples = int(len(handmade_data)*TRAIN_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = handmade_data[:training_samples]\n",
    "dev_data = handmade_data[training_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('handmade_data_train.json', 'w') as outfile:\n",
    "    json.dump(train_data, outfile)\n",
    "\n",
    "with open('handmade_data_dev.json', 'w') as outfile:\n",
    "    json.dump(dev_data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you plan to train Valuenet with this data, you can follow the steps explained in [preprocess_custom_data-01.ipynb](https://github.com/hack-with-admin-ch/aws-sagemaker-notebook-valuenet/blob/training_options/preprocess_custom_data-01.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
